{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ca2c37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T14:27:45.225740Z",
     "start_time": "2022-06-22T14:27:43.408498Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display      import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5ac06",
   "metadata": {},
   "source": [
    "# Ciclo 04 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fd59f",
   "metadata": {},
   "source": [
    "- Foi identificado itens de desconto no dataset, e como estamos interessados no faturamento do grupo essa informção não é muito interessante para alimentar o algoritmo.\n",
    "- Além disso foi identificado que do totla de invoices com letras todos estão com a quantity negativa\n",
    "- Como os stock codes ['POST' 'D' 'M' 'PADS' 'DOT' 'CRUK'] não siginificam necessariamente uma compra, então iremos removê-los. Poderia ainda ser feito uma investigação mais a fundo para ver se tem stockcode com uma letra, duas, três, etc, porém no momento nos daremos pro satisfetio ao fazer apenas essa limpeza, no proximo ciclo novas alterações serão feitas.\n",
    "- Entende-se que a coluna description não irá contribuir com a diferenciação dos clientes, ela será descartaada nesse momento.\n",
    "- Será assumido que os produtos com unit_price = 0 são brindes. E de acordo com essa assumption essas linhas serão excluidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8fb84a",
   "metadata": {},
   "source": [
    "## 3.0 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1fdca",
   "metadata": {},
   "source": [
    "- Para as variáveis numéricas foram separadas apenas as compras cujo uniy_price foram maiores que 0.04.\n",
    "- Como não existe um lat long específico para união europeia, então esse \"país\" será eliminado e também o pais \"Unspecified\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520046e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T21:30:42.397141Z",
     "start_time": "2022-06-14T21:30:42.384741Z"
    }
   },
   "source": [
    "## 4.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03daf80",
   "metadata": {},
   "source": [
    "- Como está sendo separado as compras dos charge backs é importante separar também o cálculo da feature de frequencia, pois senão estaremos calculando a frequência de compras e devoluções na mesma feature.\n",
    "- Dependendo do momento da empresa, se ela estiver no momento de scaleup, por exemplo, normalmente não se preocupa com o custo; mas sim em aumentar a base de clientes mesmo tirando dinheiro do bolso para pagar a operação. Após esse período, no momento de escala de um produto procura-se então reduzir o máximo os custos.\n",
    "- No caso será considerado que a empresa está em scaleup, com isso os custos serão considerados e mantidos.\n",
    "- Após a criação do df_monetary apareceram 27 linhas nulas, isso pode ser por conta de devoluções que entraram dentro do período do dataset mas que não contempplou também as compras. O método inner é usado apenas quando temos certeza que temos todas as linhas nas duas tabelas que será aplicado o merge.\n",
    "- No cálculo do df_recency['recency_days'] considera-sa a data df2['invoice_date'].max() como sendo a data mais atual do dataset, como se fosse a data de hoje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184f25a",
   "metadata": {},
   "source": [
    "### Ciclo 05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d187c4",
   "metadata": {},
   "source": [
    "- Tentaremos a separação do dataset com customer_id NaN e com os preenchidos e verificar se existem os invoice_code (dos customer_id faltantes) no dataset com o valor do customer_id e atribuir o mesmo customer_id para ambos.\n",
    "- Como não foi encontrado nenhum invoice_no do df_missing no df_not_missing, então será aribuído um numero aleatorio de customer_id (fora do range dos customer_ids que já existems) para aproveitar esses dados e incrementar a performance do algorítmo na determinação dos clusters. No caso o valor máximo do customer_id no df_not_missing é 18287, então será atribuído valores para o customer_ids faltantes a partir de 19000\n",
    "- Será feito um merge entree o df_missing e o df1 (original) onde irá surgir NaNs onde já existe o customer_id, dessa forma basta gerar um novo df apenas com as linhas com customer_id(x ou y) preenchidas, com os valores originais ou aleatórios.\n",
    "- Com essa alteração foi possível recuperar basicamente 25% dos dados.\n",
    "- Como entraram novos dados é necessário se fazer uma nova análise descritiva.\n",
    "- No ciclo anterior a frequência foi calculada de forma errrada, pois foi calculado o número de compras por customer.\n",
    "- A feature average recency days irá auxiliar a termos uma média de dias que as pessoas demoram para fazer uma nova compra.\n",
    "- PAra a clusterização serão considerados os clientes que gastam mais, independente da variedade de produtos, uma vez que o objetivo do negócio nesse projeto são os clientes que gastam mais.\n",
    "- Como o dataset foi separado em compras e devoluções irá aparecer 91 linhas com nas nos joins das novas features, pois são customers_ids que apenas fizeram devolução, ou seja, a data de compra deles está anterior ao período compreendido pelo dataset.\n",
    "- O uso da função shift foi para conseguirmos realizar a diferença entre duas datas de compra para um mesmo customer_id e assim estimar o tempo que o aquele id demorou para realizar uma nova compra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af27f1",
   "metadata": {},
   "source": [
    "### Ciclo 06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2f357",
   "metadata": {},
   "source": [
    "- O invoice no é a compra toda, o stock code é o código unico do produto e a quantity é a quantidade de cada produto. O Basket Size vai ser a quantidade de itens (média) por compra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381732c8",
   "metadata": {},
   "source": [
    "# 4.0 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf820f9",
   "metadata": {},
   "source": [
    "- As hipóteses num problema de clusterização serão levantadas e respondidads sempre no final após a clusterização.\n",
    "- Para a análise da EDA será utilzado o pandas_profiling que já faz a análise de dados \"automaticamente\". A EDA irá possibilitar a análise do comportamento das features mas ainda não possibilitará a chegada a alguma conclusão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff9342a",
   "metadata": {},
   "source": [
    "# 5.0 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d7163",
   "metadata": {},
   "source": [
    "- O standardscaler foi feito sem considerar o fato de que a distribuição do gross revenue está bastante concentrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4519a3cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T14:20:11.151054Z",
     "start_time": "2022-06-22T14:20:10.966914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: PWD: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!PWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48d4633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T14:20:16.094652Z",
     "start_time": "2022-06-22T14:20:15.941915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/work/Documents/repos/pa005_ds_clustering/pa005_insiders_clustering_github/insiders_clustering/references\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e84a7573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T14:27:48.905854Z",
     "start_time": "2022-06-22T14:27:48.866247Z"
    }
   },
   "outputs": [],
   "source": [
    "state = pd.read_csv('state.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b4d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InsidersClustering",
   "language": "python",
   "name": "insidersclustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
